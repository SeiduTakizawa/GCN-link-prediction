# Graph Link Prediction with Multi-Modal Features

A comprehensive link prediction system built on the Deezer Europe social network dataset, combining structural embeddings, categorical features, and graph neural networks to predict missing connections with 80%+ F1 score.

## ğŸ“Š Dataset

**Deezer Europe Social Network**
- **28,281 nodes** (users/artists)
- **92,752 edges** (connections/relationships)
- **30,979 categorical features** per node
- **Node attributes**: Music preferences, genres, demographics

## ğŸ—ï¸ Project Architecture

### Data Pipeline
```
Raw Deezer Data â†’ Feature Engineering â†’ Multi-Modal Fusion â†’ GNN Training â†’ Link Prediction
```

### Feature Engineering Stack
1. **Structural Embeddings** (64 dims) - Node2Vec on training graph
2. **Categorical Features** (256 dims) - PCA on one-hot encoded attributes  
3. **Graph Features** (10 dims) - Centrality measures and local structure
4. **Total**: 330 dimensional node representations

## ğŸš€ Key Features

- âœ… **No Data Leakage**: Strict train/test separation with isolated node handling
- âœ… **Multi-Modal Learning**: Combines structure, attributes, and graph statistics
- âœ… **Balanced Training**: Equal positive/negative edge sampling
- âœ… **Graph Neural Network**: GCN-based architecture for representation learning
- âœ… **Comprehensive Evaluation**: F1, AUC, precision, recall + similarity analysis

## ğŸ“ˆ Performance

| Metric | Score |
|--------|-------|
| **F1 Score** | **80.31%** |
| **Accuracy** | **82.14%** |
| **Precision** | **89.45%** |
| **Recall** | **72.87%** |
| **AUC** | **87.86%** |

**Baseline Comparison**: 12% improvement over cosine similarity baseline

## ğŸ› ï¸ Installation

```bash
# Clone repository
git clone https://github.com/yourusername/graph-link-prediction.git
cd graph-link-prediction

# Install dependencies
pip install torch torch-geometric pandas numpy scikit-learn networkx matplotlib tqdm

# For Kaggle/Colab environments
!pip install torch-geometric
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ deezer_europe_edges.csv          # Original graph edges
â”‚   â”œâ”€â”€ deezer_europe_features.json      # Node categorical features
â”‚   â”œâ”€â”€ train_positives.csv              # Training edges (80%)
â”‚   â””â”€â”€ test_positives.csv               # Test edges (20%)
â”‚
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ embeddings.pkl                   # Node2Vec embeddings (64 dims)
â”‚   â”œâ”€â”€ node_features_pca.pkl            # PCA categorical features (256 dims)
â”‚   â””â”€â”€ simple_graph_features.pkl        # Graph structural features (10 dims)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_gnn_model.pth              # Trained GNN weights
â”‚   â””â”€â”€ gnn_results.pkl                 # Complete results package
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_preprocessing.ipynb      # Data splitting and preparation
â”‚   â”œâ”€â”€ 02_node2vec_embeddings.ipynb    # Structural embedding generation
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb    # PCA and graph features
â”‚   â””â”€â”€ 04_gnn_training.ipynb           # Model training and evaluation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing.py               # Data loading and preprocessing
â”‚   â”œâ”€â”€ feature_engineering.py          # Feature extraction pipelines
â”‚   â”œâ”€â”€ model.py                         # GNN architecture
â”‚   â””â”€â”€ evaluation.py                   # Metrics and analysis
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ”§ Usage

### 1. Data Preparation
```python
# Split edges into train/test (no leakage)
python src/data_processing.py --input data/deezer_europe_edges.csv --output data/
```

### 2. Feature Engineering
```python
# Generate Node2Vec embeddings (structural)
python src/feature_engineering.py --mode node2vec --graph data/train_positives.csv

# Create PCA features (categorical) 
python src/feature_engineering.py --mode pca --features data/deezer_europe_features.json

# Compute graph features (centrality, clustering)
python src/feature_engineering.py --mode graph --graph data/train_positives.csv
```

### 3. Model Training
```python
# Train GNN with all features
python src/model.py --train --features features/ --epochs 400 --hidden-dim 128
```

### 4. Inference
```python
from src.model import LinkPredictor

# Load trained model
predictor = LinkPredictor.from_pretrained('models/best_gnn_model.pth')

# Predict link probability
result = predictor.predict_link(node1=1777, node2=19409)
print(f"Link probability: {result['probability']:.4f}")
# Output: Link probability: 0.9954
```

## ğŸ§  Model Architecture

### Graph Convolutional Network
```python
class LinkPredictionGNN(nn.Module):
    def __init__(self, input_dim=330, hidden_dim=128):
        # GCN Layers
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        
        # Link Prediction Head
        self.link_predictor = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
```

### Feature Fusion Strategy
```
Node Features (330 dims):
â”œâ”€â”€ Node2Vec Embeddings (64 dims)    # Structural patterns
â”œâ”€â”€ PCA Categorical (256 dims)       # Node attributes  
â””â”€â”€ Graph Statistics (10 dims)       # Centrality measures

GCN Processing:
330 dims â†’ Message Passing â†’ 128 dims learned representation

Pairwise Prediction:
[Node1: 128] + [Node2: 128] â†’ Neural Network â†’ Link Probability
```

## ğŸ“Š Key Technical Innovations

### 1. Zero-Embedding Strategy for Isolated Nodes
- Nodes appearing only in test set get zero embeddings
- Prevents data leakage while maintaining coverage
- Clear "no information" signal for the model

### 2. Multi-Scale Feature Fusion
- **Global structure**: Node2Vec captures network topology
- **Local attributes**: PCA preserves categorical information
- **Micro structure**: Graph features add centrality context

### 3. Balanced Negative Sampling
- Equal positive/negative ratios during training
- Negative edges avoid conflicts with any real connections
- Maintains realistic class distribution

## ğŸ” Evaluation & Analysis

### Performance Metrics
```python
# Standard Classification Metrics
F1 Score:    80.31%
Accuracy:    82.14% 
Precision:   89.45%
Recall:      72.87%
AUC:         87.86%

# Similarity Analysis
Connected Pairs:     Cosine Sim = 0.794 Â± 0.476
Non-Connected Pairs: Cosine Sim = 0.558 Â± 0.540
```

### Feature Importance Analysis
- **Node2Vec**: Captures long-range structural dependencies
- **PCA Features**: Essential for attribute-based connections
- **Graph Features**: Provides centrality and clustering context
- **Combined**: 12% improvement over individual feature types

## ğŸš€ Future Improvements

- [ ] **Attention Mechanisms**: Add attention-based aggregation in GCN layers
- [ ] **Temporal Dynamics**: Incorporate time-based edge formation patterns  
- [ ] **Heterogeneous Graphs**: Extend to multi-type node/edge networks
- [ ] **Scalability**: Implement mini-batch training for larger graphs
- [ ] **Explainability**: Add SHAP/LIME analysis for feature importance

## ğŸ“š References

- **Node2Vec**: Grover, A. & Leskovec, J. (2016). node2vec: Scalable Feature Learning for Networks
- **Graph Convolutional Networks**: Kipf, T. N. & Welling, M. (2017). Semi-Supervised Classification with Graph Convolutional Networks
- **Deezer Dataset**: Rozemberczki, B. & Sarkar, R. (2020). Characteristic Functions on Graphs

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“§ Contact

Vasileios papadimitriou - vasilispapadim14@gmail.com



---

â­ **Star this repo if you found it helpful!** â­
