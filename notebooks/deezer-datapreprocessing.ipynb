{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12654998,"sourceType":"datasetVersion","datasetId":7997472}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Data information\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport numpy as np\n\nedge_path = \"/kaggle/input/deezer-data/deezer_europe/deezer_europe_edges.csv\"\njson_path = \"/kaggle/input/deezer-data/deezer_europe/deezer_europe_features.json\"\n\n# ---------- Edge-list info ----------\n\nedges_df = pd.read_csv(edge_path)\nn_edges = len(edges_df)\nnodes_from_edges = set(edges_df['node_1']).union(edges_df['node_2'])\nn_nodes_edges = len(nodes_from_edges)\n\nprint(f\"EDGELIST:\")\nprint(f\"Number of edges: {n_edges}\")\nprint(f\"Number of nodes: {n_nodes_edges}\")\n\nself_loops = edges_df[edges_df['node_1'] == edges_df['node_2']]\nduplicate_edges = edges_df.duplicated(subset=['node_1', 'node_2'])\nprint(f\"- Self-loops: {len(self_loops)}\")\nprint(f\"- Duplicate edges: {duplicate_edges.sum()}\")\n\n# --- JSON FEATURES info ---\nwith open(json_path, \"r\") as f:\n    features_dict = json.load(f)\n\nn_json_nodes = len(features_dict)\nfeature_ids = set()\nfor feats in features_dict.values():\n    feature_ids.update(feats)\nn_features = len(feature_ids)\n\nempty_feature_nodes = [uid for uid, feats in features_dict.items() if len(feats) == 0]\nprint(\"\\nFEATURES JSON:\")\nprint(f\"- Nodes in JSON: {n_json_nodes}\")\nprint(f\"- Total distinct feature ids: {n_features}\")\nprint(f\"- Nodes with no features: {len(empty_feature_nodes)}\")\nif len(empty_feature_nodes) > 0:\n    print(f\"  (Sample: {empty_feature_nodes[:10]})\")\n\n# --- Overlap between nodes ---\nshared_nodes = set(map(int, features_dict.keys())) & nodes_from_edges\nprint(f\"\\nOVERLAP Edgelist <-> Features JSON:\")\nprint(f\"- Common nodes: {len(shared_nodes)}\")\nprint(f\"- Nodes only in Edgelist: {len(nodes_from_edges - set(map(int, features_dict.keys())))}\")\nprint(f\"- Nodes only in Features JSON: {len(set(map(int, features_dict.keys())) - nodes_from_edges)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T15:25:47.115049Z","iopub.execute_input":"2025-08-03T15:25:47.115374Z","iopub.status.idle":"2025-08-03T15:25:47.551257Z","shell.execute_reply.started":"2025-08-03T15:25:47.115350Z","shell.execute_reply":"2025-08-03T15:25:47.550503Z"}},"outputs":[{"name":"stdout","text":"EDGELIST:\nNumber of edges: 92752\nNumber of nodes: 28281\n- Self-loops: 0\n- Duplicate edges: 0\n\nFEATURES JSON:\n- Nodes in JSON: 28281\n- Total distinct feature ids: 30978\n- Nodes with no features: 6159\n  (Sample: ['4', '6', '7', '8', '9', '11', '12', '35', '36', '38'])\n\nOVERLAP Edgelist <-> Features JSON:\n- Common nodes: 28281\n- Nodes only in Edgelist: 0\n- Nodes only in Features JSON: 0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"\n**Data splitting for embedding generation**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport networkx as nx\nfrom sklearn.model_selection import train_test_split\nimport random\n\n# 1. Load edges\nedges_df = pd.read_csv(\"/kaggle/input/deezer-data/deezer_europe/deezer_europe_edges.csv\")\nedges = list(zip(edges_df['node_1'], edges_df['node_2']))\n\n# 2. Train/test split on positive edges\ntrain_edges, test_edges = train_test_split(edges, test_size=0.2, random_state=42)\n\n# --- Save train and test positives ---\ntrain_pos_df = pd.DataFrame(train_edges, columns=['node_1', 'node_2'])\ntrain_pos_df.to_csv('train_positives.csv', index=False)\n\n# Print number of unique nodes in train CSV\nunique_nodes_train = set(train_pos_df['node_1']).union(set(train_pos_df['node_2']))\nprint(f\"Number of unique nodes in train CSV: {len(unique_nodes_train)}\")\n\ntest_pos_df = pd.DataFrame(test_edges, columns=['node_1', 'node_2'])\ntest_pos_df.to_csv('test_positives.csv', index=False)\n\ndef check_overlap_pairs(train_edges, test_edges):\n    \"\"\"\n    Checks if any (u, v) pair exists in both train and test (order-independent).\n    \"\"\"\n    train_set = set(tuple(sorted(edge)) for edge in train_edges)\n    test_set = set(tuple(sorted(edge)) for edge in test_edges)\n    overlap = train_set.intersection(test_set)\n    return (len(overlap) > 0), overlap\n\n# Call the function and print results\noverlap_exists, overlap_pairs = check_overlap_pairs(train_edges, test_edges)\nif overlap_exists:\n    print(f\"Overlap found! Duplicated pairs: {list(overlap_pairs)[:5]} ...\")\nelse:\n    print(\"No duplicate node pairs between train and test sets.\")\n\n# 3. Create train graph with all nodes and train edges\ntrain_graph = nx.Graph()\nall_nodes = list(set([n for edge in edges for n in edge]))\ntrain_graph.add_nodes_from(all_nodes)\ntrain_graph.add_edges_from(train_edges)\n\n# 4. Generate negative samples for both splits (ensuring exclusivity)\ndef generate_negative_edges(graph, num_samples, excluded_edges):\n    neg_edges = set()\n    nodes = list(graph.nodes())\n    while len(neg_edges) < num_samples:\n        u = random.choice(nodes)\n        v = random.choice(nodes)\n        if u == v:\n            continue\n        if graph.has_edge(u, v) or (u, v) in excluded_edges or (v, u) in excluded_edges:\n            continue\n        neg_edges.add((u, v))\n    return list(neg_edges)\n\ntrain_neg_edges = generate_negative_edges(train_graph, len(train_edges), set(train_edges))\ntest_neg_edges = generate_negative_edges(train_graph, len(test_edges), set(train_edges).union(set(test_edges)))\n\n# 5. Prepare datasets for training and testing\ntrain_positive_labels = [1] * len(train_edges)\ntrain_negative_labels = [0] * len(train_neg_edges)\ntest_positive_labels = [1] * len(test_edges)\ntest_negative_labels = [0] * len(test_neg_edges)\n\ntrain_samples = train_edges + train_neg_edges\ntrain_labels = train_positive_labels + train_negative_labels\ntest_samples = test_edges + test_neg_edges\ntest_labels = test_positive_labels + test_negative_labels\n\nprint(f\"Train samples: {len(train_samples)} (positive: {len(train_edges)}, negative: {len(train_neg_edges)})\")\nprint(f\"Test samples: {len(test_samples)} (positive: {len(test_edges)}, negative: {len(test_neg_edges)})\")\nprint(f\"Total nodes in train graph: {train_graph.number_of_nodes()}\")\nprint(f\"Total edges in train graph: {train_graph.number_of_edges()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T00:16:43.428800Z","iopub.execute_input":"2025-08-04T00:16:43.429110Z","iopub.status.idle":"2025-08-04T00:16:45.935676Z","shell.execute_reply.started":"2025-08-04T00:16:43.429084Z","shell.execute_reply":"2025-08-04T00:16:45.934661Z"}},"outputs":[{"name":"stdout","text":"Number of unique nodes in train CSV: 26895\nNo duplicate node pairs between train and test sets.\nTrain samples: 148402 (positive: 74201, negative: 74201)\nTest samples: 37102 (positive: 18551, negative: 18551)\nTotal nodes in train graph: 28281\nTotal edges in train graph: 74201\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Json manipulation of empty feature ids.**","metadata":{}},{"cell_type":"code","source":"import json\nimport numpy as np\n\n# Load the user-feature JSON dictionary\nwith open('/kaggle/input/deezer-data/deezer_europe/deezer_europe_features.json', 'r') as f:\n    user_features_dict = json.load(f)\n\n# Determine the number of users (nodes)\nnum_users = len(user_features_dict)\n\n# Find the maximum feature id to get the number of features\nmax_feature_id = 0\nfor features in user_features_dict.values():\n    if features:  # handle empty list case\n        max_feature_id = max(max_feature_id, max(features))\n\nnum_features = max_feature_id + 1\n\n# Initialize the feature matrix with zeros\nX = np.zeros((num_users, num_features), dtype=np.float32)\n\n# Fill in the matrix\nfor user_str, features in user_features_dict.items():\n    user_idx = int(user_str)\n    for f in features:\n        X[user_idx, f] = 1.0\n\nprint(f\"Feature matrix shape: {X.shape}\")\nprint(f\"Feature vector of user 0: {X[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T17:24:29.726216Z","iopub.execute_input":"2025-08-03T17:24:29.726665Z","iopub.status.idle":"2025-08-03T17:24:31.187443Z","shell.execute_reply.started":"2025-08-03T17:24:29.726635Z","shell.execute_reply":"2025-08-03T17:24:31.186286Z"}},"outputs":[{"name":"stdout","text":"Feature matrix shape: (28281, 31241)\nFeature vector of user 0: [0. 0. 0. ... 0. 0. 0.]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import json\nimport numpy as np\nimport torch\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n# 1. Load JSON data\nwith open('/kaggle/input/deezer-data/deezer_europe/deezer_europe_features.json') as f:\n    raw_data = json.load(f)\n\n# 2. Parse node IDs and features\nnode_ids = sorted(int(k) for k in raw_data.keys())\nnode_features = {int(k): v for k, v in raw_data.items()}\n\nall_features = [\n    [str(f) for f in node_features[nid]]  # convert all features to str\n    for nid in node_ids\n]\n\n# Assign '<NO_FEATURE>' string to empty feature lists\nfor i, feats in enumerate(all_features):\n    if len(feats) == 0:\n        all_features[i] = ['<NO_FEATURE>']\n\nmlb = MultiLabelBinarizer()\nX = mlb.fit_transform(all_features)  # one-hot encode features\n\nx = torch.tensor(X, dtype=torch.float)\nprint(\"x.shape =\", x.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T18:25:51.111803Z","iopub.execute_input":"2025-08-03T18:25:51.112158Z","iopub.status.idle":"2025-08-03T18:25:57.653225Z","shell.execute_reply.started":"2025-08-03T18:25:51.112132Z","shell.execute_reply":"2025-08-03T18:25:57.652294Z"}},"outputs":[{"name":"stdout","text":"x.shape = torch.Size([28281, 30979])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"sparsity = 1.0 - (x.sum().item() / x.numel())\nprint(f\"Sparsity: {sparsity:.4f}\")  # e.g., > 0.99\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T18:22:58.357401Z","iopub.execute_input":"2025-08-03T18:22:58.357788Z","iopub.status.idle":"2025-08-03T18:22:58.562707Z","shell.execute_reply.started":"2025-08-03T18:22:58.357765Z","shell.execute_reply":"2025-08-03T18:22:58.562027Z"}},"outputs":[{"name":"stdout","text":"Sparsity: 0.9989\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nedges_df = pd.read_csv('/kaggle/input/deezer-data/deezer_europe/deezer_europe_edges.csv')\nall_nodes = set(edges_df['node_1']).union(edges_df['node_2'])\n\ntrain_pos_df = pd.read_csv('/kaggle/working/train_positives.csv')\ntrain_nodes = set(train_pos_df['node_1']).union(train_pos_df['node_2'])\n\nmissing_in_train = all_nodes - train_nodes\nprint(f\"# nodes in full edgelist: {len(all_nodes)}\")\nprint(f\"# nodes in train_pos_df: {len(train_nodes)}\")\nprint(f\"# nodes missing from train_pos_df: {len(missing_in_train)}\")\nprint(\"Sample missing nodes:\", list(missing_in_train)[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T20:51:46.141338Z","iopub.execute_input":"2025-08-03T20:51:46.141655Z","iopub.status.idle":"2025-08-03T20:51:46.244553Z","shell.execute_reply.started":"2025-08-03T20:51:46.141632Z","shell.execute_reply":"2025-08-03T20:51:46.243572Z"}},"outputs":[{"name":"stdout","text":"# nodes in full edgelist: 28281\n# nodes in train_pos_df: 26895\n# nodes missing from train_pos_df: 1386\nSample missing nodes: [16387, 24579, 16393, 15, 8211, 16405, 27, 16415, 16419, 41]\n","output_type":"stream"}],"execution_count":3}]}